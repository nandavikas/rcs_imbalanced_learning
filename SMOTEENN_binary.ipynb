{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JafCERGraLlj",
        "outputId": "08ed1199-696c-4a78-cc4c-f03e1242c557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/studentx/.local/lib/python3.8/site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/studentx/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/studentx/.local/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/studentx/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in /home/studentx/.local/lib/python3.8/site-packages (3.7.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studentx/.local/lib/python3.8/site-packages (from matplotlib) (6.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/studentx/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imbalanced-learn in /home/studentx/.local/lib/python3.8/site-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (from imbalanced-learn) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /home/studentx/.local/lib/python3.8/site-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /home/studentx/.local/lib/python3.8/site-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/studentx/.local/lib/python3.8/site-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studentx/.local/lib/python3.8/site-packages (from imbalanced-learn) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy in /home/studentx/miniconda3/envs/pyenv_rcs/lib/python3.8/site-packages (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "%pip install imbalanced-learn\n",
        "%pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ux6Fcas2lnm1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA-6HcdXlq48",
        "outputId": "de202021-8ff4-4ec2-e5a2-0fac1319aee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1723 entries, 0 to 1722\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   month                1723 non-null   int64 \n",
            " 1   credit_amount        1723 non-null   int64 \n",
            " 2   credit_term          1723 non-null   int64 \n",
            " 3   age                  1723 non-null   int64 \n",
            " 4   sex                  1723 non-null   object\n",
            " 5   education            1723 non-null   object\n",
            " 6   product_type         1723 non-null   object\n",
            " 7   having_children_flg  1723 non-null   int64 \n",
            " 8   region               1723 non-null   int64 \n",
            " 9   income               1723 non-null   int64 \n",
            " 10  family_status        1723 non-null   object\n",
            " 11  phone_operator       1723 non-null   int64 \n",
            " 12  is_client            1723 non-null   int64 \n",
            " 13  bad_client_target    1723 non-null   int64 \n",
            "dtypes: int64(10), object(4)\n",
            "memory usage: 188.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('good_customer.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "fbkIoFP8ltI5",
        "outputId": "5847f145-73a8-42d7-d18f-6bdacb1b2da8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>credit_term</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>education</th>\n",
              "      <th>product_type</th>\n",
              "      <th>having_children_flg</th>\n",
              "      <th>region</th>\n",
              "      <th>income</th>\n",
              "      <th>family_status</th>\n",
              "      <th>phone_operator</th>\n",
              "      <th>is_client</th>\n",
              "      <th>bad_client_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7000</td>\n",
              "      <td>12</td>\n",
              "      <td>39</td>\n",
              "      <td>male</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Cell phones</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>21000</td>\n",
              "      <td>Another</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19000</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>male</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Household appliances</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>17000</td>\n",
              "      <td>Another</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>29000</td>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "      <td>female</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Household appliances</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>31000</td>\n",
              "      <td>Another</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10000</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>male</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Cell phones</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>31000</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>14500</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Cell phones</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26000</td>\n",
              "      <td>Married</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>32500</td>\n",
              "      <td>24</td>\n",
              "      <td>47</td>\n",
              "      <td>female</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Furniture</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26000</td>\n",
              "      <td>Married</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>8000</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>male</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Computers</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>21000</td>\n",
              "      <td>Another</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>20000</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Household appliances</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33000</td>\n",
              "      <td>Married</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>26000</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Cell phones</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31000</td>\n",
              "      <td>Another</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>15000</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "      <td>Secondary special education</td>\n",
              "      <td>Household appliances</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>26000</td>\n",
              "      <td>Another</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   month  credit_amount  credit_term  age     sex  \\\n",
              "0      1           7000           12   39    male   \n",
              "1      1          19000            6   20    male   \n",
              "2      1          29000           12   23  female   \n",
              "3      1          10000           12   30    male   \n",
              "4      1          14500           12   25  female   \n",
              "5      1          32500           24   47  female   \n",
              "6      1           8000            3   23    male   \n",
              "7      1          20000           10   25  female   \n",
              "8      1          26000            6   21  female   \n",
              "9      1          15000           24   25  female   \n",
              "\n",
              "                     education          product_type  having_children_flg  \\\n",
              "0  Secondary special education           Cell phones                    0   \n",
              "1  Secondary special education  Household appliances                    1   \n",
              "2  Secondary special education  Household appliances                    0   \n",
              "3  Secondary special education           Cell phones                    1   \n",
              "4             Higher education           Cell phones                    0   \n",
              "5  Secondary special education             Furniture                    0   \n",
              "6             Higher education             Computers                    0   \n",
              "7             Higher education  Household appliances                    0   \n",
              "8  Secondary special education           Cell phones                    0   \n",
              "9  Secondary special education  Household appliances                    1   \n",
              "\n",
              "   region  income family_status  phone_operator  is_client  bad_client_target  \n",
              "0       2   21000       Another               0          0                  0  \n",
              "1       2   17000       Another               3          1                  0  \n",
              "2       2   31000       Another               2          0                  0  \n",
              "3       2   31000     Unmarried               3          1                  0  \n",
              "4       2   26000       Married               0          1                  0  \n",
              "5       2   26000       Married               0          1                  0  \n",
              "6       2   21000       Another               0          1                  0  \n",
              "7       0   33000       Married               2          1                  0  \n",
              "8       0   31000       Another               2          1                  0  \n",
              "9       2   26000       Another               3          0                  0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaEWjQIGlvGt",
        "outputId": "f093ae68-1a53-486e-e444-9c9c5c6eaf8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>credit_term</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>education</th>\n",
              "      <th>product_type</th>\n",
              "      <th>having_children_flg</th>\n",
              "      <th>region</th>\n",
              "      <th>income</th>\n",
              "      <th>family_status</th>\n",
              "      <th>phone_operator</th>\n",
              "      <th>is_client</th>\n",
              "      <th>bad_client_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [month, credit_amount, credit_term, age, sex, education, product_type, having_children_flg, region, income, family_status, phone_operator, is_client, bad_client_target]\n",
              "Index: []"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows_with_nan = df.isna().any(axis=1)\n",
        "\n",
        "# Display rows that contain at least one NaN value\n",
        "nan_rows = df[rows_with_nan]\n",
        "\n",
        "nan_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "45CMKVDflxPr",
        "outputId": "69c5d144-9618-4caf-fe18-af790828cc2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>credit_term</th>\n",
              "      <th>age</th>\n",
              "      <th>having_children_flg</th>\n",
              "      <th>region</th>\n",
              "      <th>income</th>\n",
              "      <th>phone_operator</th>\n",
              "      <th>is_client</th>\n",
              "      <th>bad_client_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.708067</td>\n",
              "      <td>29264.654672</td>\n",
              "      <td>11.546721</td>\n",
              "      <td>35.911782</td>\n",
              "      <td>0.428323</td>\n",
              "      <td>1.681370</td>\n",
              "      <td>32652.350551</td>\n",
              "      <td>1.125363</td>\n",
              "      <td>0.604759</td>\n",
              "      <td>0.113755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.538420</td>\n",
              "      <td>27926.778301</td>\n",
              "      <td>6.548354</td>\n",
              "      <td>13.120203</td>\n",
              "      <td>0.494979</td>\n",
              "      <td>0.704256</td>\n",
              "      <td>20913.193158</td>\n",
              "      <td>1.015822</td>\n",
              "      <td>0.489044</td>\n",
              "      <td>0.317606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>13000.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>21500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>27000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>34000.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>38000.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>301000.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>401000.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             month  credit_amount  credit_term          age  \\\n",
              "count  1723.000000    1723.000000  1723.000000  1723.000000   \n",
              "mean      6.708067   29264.654672    11.546721    35.911782   \n",
              "std       3.538420   27926.778301     6.548354    13.120203   \n",
              "min       1.000000    5000.000000     3.000000    18.000000   \n",
              "25%       3.000000   13000.000000     6.000000    26.000000   \n",
              "50%       7.000000   21500.000000    12.000000    32.000000   \n",
              "75%      10.000000   34000.000000    12.000000    44.000000   \n",
              "max      12.000000  301000.000000    36.000000    90.000000   \n",
              "\n",
              "       having_children_flg       region         income  phone_operator  \\\n",
              "count          1723.000000  1723.000000    1723.000000     1723.000000   \n",
              "mean              0.428323     1.681370   32652.350551        1.125363   \n",
              "std               0.494979     0.704256   20913.193158        1.015822   \n",
              "min               0.000000     0.000000    1000.000000        0.000000   \n",
              "25%               0.000000     2.000000   21000.000000        0.000000   \n",
              "50%               0.000000     2.000000   27000.000000        1.000000   \n",
              "75%               1.000000     2.000000   38000.000000        2.000000   \n",
              "max               1.000000     2.000000  401000.000000        4.000000   \n",
              "\n",
              "         is_client  bad_client_target  \n",
              "count  1723.000000        1723.000000  \n",
              "mean      0.604759           0.113755  \n",
              "std       0.489044           0.317606  \n",
              "min       0.000000           0.000000  \n",
              "25%       0.000000           0.000000  \n",
              "50%       1.000000           0.000000  \n",
              "75%       1.000000           0.000000  \n",
              "max       1.000000           1.000000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFBdRmqAbdVe",
        "outputId": "c5107967-e23e-440f-9e0e-57dee592d7ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bad_client_target\n",
              "0    1527\n",
              "1    1500\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"sex\"] = label_encoder.fit_transform(df[\"sex\"])\n",
        "df[\"education\"] = label_encoder.fit_transform(df[\"education\"])\n",
        "df[\"product_type\"] = label_encoder.fit_transform(df[\"product_type\"])\n",
        "df[\"family_status\"] = label_encoder.fit_transform(df[\"family_status\"])\n",
        "\n",
        "\n",
        "X = df.drop(\"bad_client_target\", axis=1)\n",
        "y = df[\"bad_client_target\"]\n",
        "\n",
        "smote = SMOTE(sampling_strategy={1: 1500}, k_neighbors=4, random_state=10)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "\n",
        "resampled_quality_distribution = pd.Series(y_resampled).value_counts().sort_index()\n",
        "\n",
        "resampled_quality_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-16K9GibaON",
        "outputId": "ccbe1638-06d0-4e0e-adbd-f802961f627f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance on Scaled Resampled Data:\n",
            "Decision Tree Accuracy: 0.8375\n",
            "SVM Accuracy: 0.8230\n",
            "Logistic Regression Accuracy: 0.7358\n",
            "Naive Bayes Accuracy: 0.7160\n",
            "\n",
            "Performance on Scaled Original Data:\n",
            "Decision Tree Accuracy: 0.7935\n",
            "SVM Accuracy: 0.8910\n",
            "Logistic Regression Accuracy: 0.8886\n",
            "Naive Bayes Accuracy: 0.8283\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.25, random_state=10)\n",
        "\n",
        "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=10)\n",
        "\n",
        "classifiers = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=10),\n",
        "    \"SVM\": SVC(random_state=10),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=10),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "def train_evaluate_classifiers(classifiers, X_train, y_train, X_test, y_test):\n",
        "    accuracies = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        # Train the classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies[name] = accuracy\n",
        "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "\n",
        "scaler_resampled = StandardScaler()\n",
        "X_train_resampled_scaled = scaler_resampled.fit_transform(X_train_resampled)\n",
        "X_test_resampled_scaled = scaler_resampled.transform(X_test_resampled)\n",
        "\n",
        "scaler_original = StandardScaler()\n",
        "X_train_original_scaled = scaler_original.fit_transform(X_train_original)\n",
        "X_test_original_scaled = scaler_original.transform(X_test_original)\n",
        "\n",
        "print(\"Performance on Scaled Resampled Data:\")\n",
        "resampled_accuracies_scaled = train_evaluate_classifiers(classifiers, X_train_resampled_scaled, y_train_resampled, X_test_resampled_scaled, y_test_resampled)\n",
        "\n",
        "print(\"\\nPerformance on Scaled Original Data:\")\n",
        "original_accuracies_scaled = train_evaluate_classifiers(classifiers, X_train_original_scaled, y_train_original, X_test_original_scaled, y_test_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkKkahDDbTb8",
        "outputId": "c9041b38-ccdc-4174-e4d8-3078f338d7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing Decision Tree...\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "\n",
            "\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "\n",
            "\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
            "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
            "Best parameters for Decision Tree: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "\n",
            "Optimizing SVM...\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time=   0.1s\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time=   0.1s\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time=   0.1s\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.1s\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time=   0.1s\n",
            "[CV] END ...............................C=0.1, kernel=linear; total time=   0.1s\n",
            "[CV] END .................................C=0.1, kernel=poly; total time=   0.1s\n",
            "[CV] END .................................C=0.1, kernel=poly; total time=   0.2s\n",
            "[CV] END .................................C=0.1, kernel=poly; total time=   0.2s\n",
            "[CV] END ...................................C=1, kernel=poly; total time=   0.1s\n",
            "[CV] END .................................C=0.1, kernel=poly; total time=   0.2s\n",
            "[CV] END .................................C=0.1, kernel=poly; total time=   0.2s\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ...................................C=1, kernel=poly; total time=   0.1s\n",
            "[CV] END .................................C=1, kernel=linear; total time=   0.2s\n",
            "[CV] END ...................................C=1, kernel=poly; total time=   0.1s\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.2s\n",
            "[CV] END .................................C=1, kernel=linear; total time=   0.2s\n",
            "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ....................................C=1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ....................................C=1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ....................................C=1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ....................................C=1, kernel=rbf; total time=   0.2s\n",
            "[CV] END ....................................C=1, kernel=rbf; total time=   0.2s\n",
            "[CV] END .................................C=1, kernel=linear; total time=   0.2s\n",
            "[CV] END .................................C=1, kernel=linear; total time=   0.2s\n",
            "[CV] END .................................C=1, kernel=linear; total time=   0.2s\n",
            "[CV] END ...................................C=1, kernel=poly; total time=   0.1s\n",
            "[CV] END ...................................C=1, kernel=poly; total time=   0.1s\n",
            "[CV] END ...................................C=10, kernel=rbf; total time=   0.1s\n",
            "[CV] END ...................................C=10, kernel=rbf; total time=   0.2s\n",
            "[CV] END ...................................C=10, kernel=rbf; total time=   0.2s\n",
            "[CV] END ...................................C=10, kernel=rbf; total time=   0.1s\n",
            "[CV] END ...................................C=10, kernel=rbf; total time=   0.2s\n",
            "[CV] END ..................................C=10, kernel=poly; total time=   0.1s\n",
            "[CV] END ..................................C=10, kernel=poly; total time=   0.2s\n",
            "[CV] END ..................................C=10, kernel=poly; total time=   0.2s\n",
            "[CV] END ..................................C=10, kernel=poly; total time=   0.2s\n",
            "[CV] END ..................................C=10, kernel=poly; total time=   0.2s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   0.5s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   0.5s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   0.5s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   0.5s\n",
            "[CV] END ................................C=10, kernel=linear; total time=   0.5s\n",
            "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n",
            "\n",
            "Optimizing Logistic Regression...\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ..C=0.001, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ..C=0.001, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ..C=0.001, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ..C=0.001, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ..C=0.001, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.001, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.001, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.001, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.01, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.01, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.01, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.01, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.01, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ...C=0.01, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.01, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END C=0.01, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.01, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.01, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=0.1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s[CV] END .......C=0.1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "\n",
            "[CV] END .......C=0.1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=0.1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=0.1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s[CV] END C=1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "\n",
            "[CV] END C=1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=1, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......C=1, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .........C=1, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .C=1, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=1, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=10, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=10, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=10, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=10, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=10, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=10, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ........C=10, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=10, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=10, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END ......C=100, l1_ratio=None, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=100, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=100, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=100, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=100, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END ....C=100, l1_ratio=None, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.2, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.2, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.2, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.4, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.4, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.4, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.6, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.6, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.6, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l1, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END .......C=100, l1_ratio=0.8, penalty=l2, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END .....C=100, l1_ratio=0.8, penalty=none, solver=saga; total time=   0.0s\n",
            "[CV] END C=100, l1_ratio=0.8, penalty=elasticnet, solver=saga; total time=   0.0s\n",
            "Best parameters for Logistic Regression: {'C': 0.1, 'l1_ratio': 0.6, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
            "\n",
            "Optimizing Naive Bayes...\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-09; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-08; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-07; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "[CV] END ................................var_smoothing=1e-06; total time=   0.0s\n",
            "Best parameters for Naive Bayes: {'var_smoothing': 1e-09}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1172: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "30 fits failed out of a total of 600.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/studentx/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/studentx/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/home/studentx/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1179, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.50088106 0.71189427        nan 0.71629956 0.50088106 0.71189427\n",
            " 0.70088106 0.71629956 0.50088106 0.71189427 0.50088106 0.71629956\n",
            " 0.50088106 0.71189427 0.50088106 0.71629956 0.50088106 0.71189427\n",
            " 0.50088106 0.71629956 0.70572687 0.71277533        nan 0.71629956\n",
            " 0.70572687 0.71277533 0.71365639 0.71629956 0.70572687 0.71277533\n",
            " 0.71145374 0.71629956 0.70572687 0.71277533 0.70837004 0.71629956\n",
            " 0.70572687 0.71277533 0.71101322 0.71629956 0.71718062 0.71718062\n",
            "        nan 0.71629956 0.71718062 0.71718062 0.71806167 0.71629956\n",
            " 0.71718062 0.71718062 0.71674009 0.71629956 0.71718062 0.71718062\n",
            " 0.71894273 0.71629956 0.71718062 0.71718062 0.71806167 0.71629956\n",
            " 0.71718062 0.71674009        nan 0.71629956 0.71718062 0.71674009\n",
            " 0.71718062 0.71629956 0.71718062 0.71674009 0.71718062 0.71629956\n",
            " 0.71718062 0.71674009 0.71718062 0.71629956 0.71718062 0.71674009\n",
            " 0.71674009 0.71629956 0.71629956 0.71629956        nan 0.71629956\n",
            " 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956\n",
            " 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956\n",
            " 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956\n",
            "        nan 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956\n",
            " 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956\n",
            " 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956 0.71629956]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "param_grids = {\n",
        "    \"Decision Tree\": {\n",
        "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly']\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "        'solver': ['saga'],\n",
        "        'l1_ratio': [None, 0.2, 0.4, 0.6, 0.8]  # Use None for other penalties, specific values for 'elasticnet'\n",
        "    },\n",
        "    \"Naive Bayes\": {\n",
        "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
        "    }\n",
        "}\n",
        "\n",
        "def hyperparameter_optimization(classifiers, param_grids, X_train, y_train):\n",
        "    best_params = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        print(f\"Optimizing {name}...\")\n",
        "\n",
        "        # Custom iterator to skip incompatible combinations\n",
        "        param_iter = (params for params in ParameterGrid(param_grids[name])\n",
        "                      if not (params['penalty'] == 'elasticnet' and params['l1_ratio'] is None))\n",
        "\n",
        "        # Grid search for hyperparameters\n",
        "        grid_search = GridSearchCV(clf, param_grid=param_grids[name], cv=5, n_jobs=-1, verbose=2)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Store best parameters\n",
        "        best_params[name] = grid_search.best_params_\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\\n\")\n",
        "\n",
        "    return best_params\n",
        "\n",
        "\n",
        "optimized_parameters = hyperparameter_optimization(classifiers, param_grids, X_train_resampled_scaled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Decision Tree': {'max_depth': None,\n",
              "  'min_samples_leaf': 2,\n",
              "  'min_samples_split': 5},\n",
              " 'SVM': {'C': 10, 'kernel': 'rbf'},\n",
              " 'Logistic Regression': {'C': 0.1,\n",
              "  'l1_ratio': 0.6,\n",
              "  'penalty': 'elasticnet',\n",
              "  'solver': 'saga'},\n",
              " 'Naive Bayes': {'var_smoothing': 1e-09}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimized_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_decision_boundaries(X, y, model, title):\n",
        "    # Define the grid range\n",
        "    h = 0.02  # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predict class for each point in the grid\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\", s=20)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JM-z_nLgbOWM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model initializations\n",
        "classifiers = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the 'type' column to numerical values using Label Encoding\n",
        "label_encoder = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for Decision Tree: 0.8530\n",
            "Accuracy for Decision Tree: 0.8526\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89       444\n",
            "           1       0.77      0.79      0.78       214\n",
            "\n",
            "    accuracy                           0.85       658\n",
            "   macro avg       0.83      0.84      0.83       658\n",
            "weighted avg       0.85      0.85      0.85       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for SVM: 0.5437\n",
            "Accuracy for SVM: 0.6748\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.81       444\n",
            "           1       0.00      0.00      0.00       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.34      0.50      0.40       658\n",
            "weighted avg       0.46      0.67      0.54       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Logistic Regression: 0.6089\n",
            "Accuracy for Logistic Regression: 0.6702\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       444\n",
            "           1       0.48      0.15      0.23       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.59      0.54      0.51       658\n",
            "weighted avg       0.62      0.67      0.61       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Naive Bayes: 0.6806\n",
            "Accuracy for Naive Bayes: 0.6702\n",
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72       444\n",
            "           1       0.50      0.73      0.59       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.66      0.69      0.66       658\n",
            "weighted avg       0.72      0.67      0.68       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Decision Tree: 0.8618\n",
            "Accuracy for Decision Tree: 0.8617\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90       444\n",
            "           1       0.79      0.79      0.79       214\n",
            "\n",
            "    accuracy                           0.86       658\n",
            "   macro avg       0.84      0.84      0.84       658\n",
            "weighted avg       0.86      0.86      0.86       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for SVM: 0.5437\n",
            "Accuracy for SVM: 0.6748\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.81       444\n",
            "           1       0.00      0.00      0.00       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.34      0.50      0.40       658\n",
            "weighted avg       0.46      0.67      0.54       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Logistic Regression: 0.6089\n",
            "Accuracy for Logistic Regression: 0.6702\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       444\n",
            "           1       0.48      0.15      0.23       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.59      0.54      0.51       658\n",
            "weighted avg       0.62      0.67      0.61       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Naive Bayes: 0.6806\n",
            "Accuracy for Naive Bayes: 0.6702\n",
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72       444\n",
            "           1       0.50      0.73      0.59       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.66      0.69      0.66       658\n",
            "weighted avg       0.72      0.67      0.68       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Decision Tree: 0.8527\n",
            "Accuracy for Decision Tree: 0.8526\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       444\n",
            "           1       0.77      0.78      0.77       214\n",
            "\n",
            "    accuracy                           0.85       658\n",
            "   macro avg       0.83      0.83      0.83       658\n",
            "weighted avg       0.85      0.85      0.85       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for SVM: 0.5437\n",
            "Accuracy for SVM: 0.6748\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.81       444\n",
            "           1       0.00      0.00      0.00       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.34      0.50      0.40       658\n",
            "weighted avg       0.46      0.67      0.54       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Logistic Regression: 0.6089\n",
            "Accuracy for Logistic Regression: 0.6702\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       444\n",
            "           1       0.48      0.15      0.23       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.59      0.54      0.51       658\n",
            "weighted avg       0.62      0.67      0.61       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Naive Bayes: 0.6806\n",
            "Accuracy for Naive Bayes: 0.6702\n",
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72       444\n",
            "           1       0.50      0.73      0.59       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.66      0.69      0.66       658\n",
            "weighted avg       0.72      0.67      0.68       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Decision Tree: 0.8541\n",
            "Accuracy for Decision Tree: 0.8541\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       444\n",
            "           1       0.78      0.78      0.78       214\n",
            "\n",
            "    accuracy                           0.85       658\n",
            "   macro avg       0.83      0.83      0.83       658\n",
            "weighted avg       0.85      0.85      0.85       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for SVM: 0.5437\n",
            "Accuracy for SVM: 0.6748\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.81       444\n",
            "           1       0.00      0.00      0.00       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.34      0.50      0.40       658\n",
            "weighted avg       0.46      0.67      0.54       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Logistic Regression: 0.6089\n",
            "Accuracy for Logistic Regression: 0.6702\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       444\n",
            "           1       0.48      0.15      0.23       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.59      0.54      0.51       658\n",
            "weighted avg       0.62      0.67      0.61       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Naive Bayes: 0.6806\n",
            "Accuracy for Naive Bayes: 0.6702\n",
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72       444\n",
            "           1       0.50      0.73      0.59       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.66      0.69      0.66       658\n",
            "weighted avg       0.72      0.67      0.68       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Decision Tree: 0.8580\n",
            "Accuracy for Decision Tree: 0.8587\n",
            "Classification Report for Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90       444\n",
            "           1       0.79      0.77      0.78       214\n",
            "\n",
            "    accuracy                           0.86       658\n",
            "   macro avg       0.84      0.83      0.84       658\n",
            "weighted avg       0.86      0.86      0.86       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score for SVM: 0.5437\n",
            "Accuracy for SVM: 0.6748\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.81       444\n",
            "           1       0.00      0.00      0.00       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.34      0.50      0.40       658\n",
            "weighted avg       0.46      0.67      0.54       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Logistic Regression: 0.6089\n",
            "Accuracy for Logistic Regression: 0.6702\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       444\n",
            "           1       0.48      0.15      0.23       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.59      0.54      0.51       658\n",
            "weighted avg       0.62      0.67      0.61       658\n",
            "\n",
            "--------------------------------------------------\n",
            "F1 Score for Naive Bayes: 0.6806\n",
            "Accuracy for Naive Bayes: 0.6702\n",
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72       444\n",
            "           1       0.50      0.73      0.59       214\n",
            "\n",
            "    accuracy                           0.67       658\n",
            "   macro avg       0.66      0.69      0.66       658\n",
            "weighted avg       0.72      0.67      0.68       658\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/studentx/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy_results = {name: [] for name in classifiers}\n",
        "f1_score_results = {name: [] for name in classifiers}\n",
        "strategies = [\"auto\", \"minority\", \"all\", \"not majority\", \"not minority\"]\n",
        "\n",
        "smote = SMOTE(sampling_strategy=\"auto\", random_state=10, k_neighbors=4)\n",
        "enn = EditedNearestNeighbours(sampling_strategy=\"auto\", n_neighbors=4)\n",
        "\n",
        "for strategy in strategies:\n",
        "    # Create SMOTEENN instance with dynamic n_neighbors\n",
        "    smote_enn = SMOTEENN(\n",
        "        sampling_strategy=strategy, random_state=10, smote=smote, enn=enn\n",
        "    )\n",
        "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_resampled, y_resampled, test_size=0.3, random_state=10\n",
        "    )\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        predictions = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        accuracy_results[name].append(accuracy)\n",
        "        f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
        "        f1_score_results[name].append(f1)\n",
        "        print(f\"F1 Score for {name}: {f1:.4f}\")\n",
        "        print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
        "        print(\n",
        "            f\"Classification Report for {name}:\\n\",\n",
        "            classification_report(y_test, predictions),\n",
        "        )\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the results for each undersampler\n",
        "plt.figure(figsize=(12, 7))\n",
        "for name, accuracies in accuracy_results.items():\n",
        "    plt.plot(strategies, accuracies, label=name, marker=\"o\")\n",
        "\n",
        "# plt.title(f\"Model Accuracy vs. Imbalance Level ({sampler_name})\")\n",
        "plt.title(f\"Model Accuracy vs. Imbalance Level  (SMOTEENN)\")\n",
        "plt.xlabel(\"Number of Samples After Hybrid Sampling\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the results for each undersampler\n",
        "plt.figure(figsize=(12, 7))\n",
        "for name, f1_scores in f1_score_results.items():\n",
        "    plt.plot(strategies, f1_scores, label=name, marker=\"o\", linestyle=\"--\")\n",
        "\n",
        "# plt.title(f\"Model Accuracy vs. Imbalance Level ({sampler_name})\")\n",
        "plt.title(f\"Model F1 Score vs. Imbalance Level  (SMOTEENN)\")\n",
        "plt.xlabel(\"Number of Samples After Hybrid Sampling\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
